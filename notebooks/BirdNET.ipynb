{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "from datetime import datetime\n",
    "from multiprocessing import Manager\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from birdnetlib import Recording\n",
    "from birdnetlib.analyzer import Analyzer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m REPO_ROOT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[1;32m      2\u001b[0m METADATA_DIR \u001b[38;5;241m=\u001b[39m Path(REPO_ROOT) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mRAW_DIR = Path(\"/media/nilomr/SONGDATA/raw/phenoscale_2024_pilot/\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mDETECTIONS_DIR = Path(REPO_ROOT, \"data\", \"derived\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03mprint(f\"Found {len(file_paths)} files\")\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "REPO_ROOT = os.path.dirname(os.path.abspath(__file__))\n",
    "METADATA_DIR = Path(REPO_ROOT) / \"metadata\"\n",
    "METADATA_DIR = \"data/pilot_metadata.csv\"\n",
    "\"\"\"\n",
    "RAW_DIR = Path(\"/media/nilomr/SONGDATA/raw/phenoscale_2024_pilot/\")\n",
    "DETECTIONS_DIR = Path(REPO_ROOT, \"data\", \"derived\")\n",
    "DETECTIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# read in the metadata json file\n",
    "with open(Path(METADATA_DIR, \"fileindex.json\"), \"r\", encoding=\"utf-8\") as jf:\n",
    "    fileindex = json.load(jf)\n",
    "\n",
    "file_paths = [\n",
    "    Path(RAW_DIR, path)\n",
    "    for k, v in fileindex.items()\n",
    "    for sk, sv in v.items()\n",
    "    for path in sv\n",
    "]\n",
    "\n",
    "# print folder names in file_paths\n",
    "print(\"Folder names in file_paths:\")\n",
    "print(pd.Series([path.parent.name for path in file_paths]).value_counts())\n",
    "\n",
    "existing_files = {\n",
    "    (file.stem.split(\"_\", 1)[0], file.stem.split(\"_\", 1)[1])\n",
    "    for file in DETECTIONS_DIR.iterdir()\n",
    "    if file.suffix == \".json\"\n",
    "}\n",
    "\n",
    "file_paths = [\n",
    "    path\n",
    "    for path in tqdm(file_paths)\n",
    "    if path.suffix in [\".wav\", \".WAV\"]\n",
    "    and os.path.getsize(path) > 10\n",
    "    and (path.parent.name, path.stem) not in existing_files\n",
    "]\n",
    "\n",
    "print(f\"Found {len(file_paths)} files\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──── MAIN ───────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Load and initialize the BirdNET-Analyzer model\n",
    "analyzer = Analyzer(version=\"2.4\")\n",
    "\n",
    "# Create a shared queue to store the detections\n",
    "manager = Manager()\n",
    "detections_queue = manager.Queue()\n",
    "\n",
    "\n",
    "def process_file(file_path):\n",
    "    date = datetime.strptime(file_path.stem.split(\"_\")[0], \"%Y%m%d\")\n",
    "    dir_name = file_path.parent.name\n",
    "\n",
    "    recording = Recording(\n",
    "        analyzer,\n",
    "        str(file_path),\n",
    "        lat=51.775036,\n",
    "        lon=-1.336488,\n",
    "        date=date,\n",
    "        min_conf=0.80,\n",
    "    )\n",
    "    log_date = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    log_file = Path(REPO_ROOT, \"logs\", f\"{log_date}.log\")\n",
    "    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        with contextlib.redirect_stdout(f):\n",
    "            recording.analyze()\n",
    "            recording.extract_embeddings()\n",
    "\n",
    "    detections_queue.put(\n",
    "        [file_path.stem, dir_name, recording.detections, recording.embeddings]\n",
    "    )\n",
    "\n",
    "\n",
    "def save_detections(data):\n",
    "    with open(\n",
    "        Path(DETECTIONS_DIR, f\"{data[1]}_{data[0]}.json\"),\n",
    "        \"w\",\n",
    "        encoding=\"utf-8\",\n",
    "    ) as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"file_name\": data[0],\n",
    "                \"dir_name\": data[1],\n",
    "                \"detections\": data[2],\n",
    "                \"embeddings\": data[3],\n",
    "            },\n",
    "            f,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "\n",
    "def process_file_and_save(file_path):\n",
    "    process_file(file_path)\n",
    "    while not detections_queue.empty():\n",
    "        data = detections_queue.get()\n",
    "        save_detections(data)\n",
    "\n",
    "\n",
    "def process_files(file_paths):\n",
    "    with tqdm(total=len(file_paths), desc=\"Processing files\") as pbar:\n",
    "        ncore = os.cpu_count()\n",
    "        print(f\"Using {ncore} cpus\")\n",
    "        pool = multiprocessing.Pool(processes=ncore)\n",
    "        for _ in pool.imap_unordered(process_file_and_save, file_paths):\n",
    "            pbar.update(1)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──── RUN PROCESS ────────────────────────────────────────────────────────────\n",
    "\n",
    "process_files(file_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvbirdnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
